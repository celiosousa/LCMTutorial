[["index.html", "Supervised Classification with Google Earth Engine Introduction and overview", " Supervised Classification with Google Earth Engine Celio Sousa (celio.h.resendedesousa@nasa.gov) 2022-03-17 Introduction and overview Disclaimer: This training material has been developed free-of-charge for educational purposes only and without any commercial interest. Some images and figures of this tutorial may have been reproduced from open sources and are citted accordingly, unless they were created by the author. If you believe any material shown in this course may be infriging a copyright, please let us know and we will remove it or take appropriate corrective action. Write something like: In part 1 of this course we will cover yada yada yada. In part 2..... "],["part-1-basics-fundamentals.html", "Chapter 1 Part 1 - Basics &amp; Fundamentals 1.1 Programming and Remote Sensing Basics 1.2 Image Manipulation", " Chapter 1 Part 1 - Basics &amp; Fundamentals 1.1 Programming and Remote Sensing Basics 1.1.1 Remote Sensing Language A) Definition The term Remote sensing has been variously defined. Some of its early definitions include: [...] the art or science of telling something about an object without touching it .(Fischer et al., 1976) Remote sensing is the acquisition of physical data of an object without touch or contact. (Lintz and Simonett, 1976) Remote sensing is the observation of a target by a device separated from it by some distance. (Barrett and Curtis, 1976) The term remote sensing in its broadest sense means &quot;reconnaissance at a distance.&quot; (Colwell, 1966) Thus, in the context of this training, we can define Remote Sensing as the science of acquiring information about a given target, object or phenomenon on the surface of the Earth by sensors on-board various platforms orbiting our planet. B) Building blocks of remote sensing Although the many different methods for collection, processing and interpretation of remotely sense data can vary widely, they will always have the following essential components: Figure 1.1: Basic components of a remote sensing system. Energy Source The source of the electromagnetic radiation/energy (EMR) is the first requirement of any remote sensing process. The electromagnetic spectrum is used to &quot;classify&quot; the EMR according to to its wavelength: Figure 1.2: The Electromagnetic Spectrum Depending on the source of energy they are using, the different remote sensing systems can be classified as active or passive. Active sensors will produce its own source of energy for the illumination of the target. They will emit the energy toward the target being investigated and the energy reflected by this target is detected and measured by the sensor. Usually, these sensors operate in the microwave range of the electromagnetic spectrum. On the other hand, passive sensors only measures the energy that is naturally available, usually from the sun. These sensors can only be used to detect the energy being reflected during the time when the sun is illuminating the Earth. These sensors usually measure energy from the optical range (visible, near infrared, short-wave infrared and thermal infrared). Figure 1.3: Remote sensing can be classified as Passive or Active based on the source of energy. You can also think about these concepts of active and passive using a handheld photogarphic camera as an example: When photographing a target in the dark, the camera flash will provide the energy necessary to illuminate the target. Therefore, in that case, the camera is an active sensor. On the other hand, this same camera will be a passive sensor when you are photographing a target or object during the day, when the target being illuminated by sun light and no flash is necessary. Interaction with the target/object The most common medium in between the source and target is the atmosphere. This is where the firt interaction ocurrs. As the EMR travel from its source to the target, it will come in contact with and interact different atmosphere constituents: aerosols, water vapor, solid particles, ect. Secondly, once the EMR makes its way through the atmospherethe to the target, it will interact with it depending on the target properties and energy wavelength. The EMR can have different types of interaction when it encounters matter; whether it is gas, solid or gas: it can be transmitted (that is, it passes through the target), absorbed (that is, the target absorbs the energy usually increasing its temperature as a result), emitted (that is, energy is emitted from all matter at temperatures above the absolute zero of 0 Kelvins), scattered (that is, deflected in every direction) and reflected (that is, energy bounces off the target's surface and its direction is usually a function of target structure and texture). Keep in mind: All targets can show different proportions of each of these interactions. Recording of the energy by the sensor The sensor - often onboard of airplanes or satellites in space - will measure the returning EMR after it has interacted with the target and the atmosphere. This measurement is converted into a digital image with discrete values in units of digital number (DN) for each image pixel. Depending on the sensor, these resulting images will have different characteristiscs (or resolutions). They are: Spatial Resolution: usually known as &quot;pixel size&quot;. It refers to the sensor's ability to discriminate different objects/targets. A higher spatial resolution means a smaller pixel size which, in turn, means that smaller objects can be distinguishable as separate targets. Spectral Resolution: Different sensors will measure the EMR at specific ranges (or wavelengths), usually called bands. Thus, the spectral resolution of a sensor usually refers to the number and bandwith of these bands. Radiometric Resolution: Usually measured in bits, it refers to the sensor's ability to detect the smallest change in the spectral reflectance among different targets. For example, a 8-bit image will have 256 levels of brightness while a 16-bit image has 65,536 levels of brightness. Temporal resolution (sensors onboard satellites): is the time required for the satellite to collect two images at the same geographic location on Earth. Higher temporal resolution means less time for revisiting the same location. However, temporal resolution is usually inverselly proportional to spatial resolution: The larger the pixel size, the larger area the sensor will cover which means less time until the next revisit. Transmission, Reception, and Processing The EMR recorded by the sensor is transmitted in an electronic form to a receiving station on Earth where the data is processed and stored. Analysis and Interpretation (we are here!) This is where this training is focused on! The EMR was transformed into a digital dataset where we can use specialized instruments/hardware/software to extract information about the target observed. This final component of Remote Sensing is achieved when we apply the extracted information to solve a particular problem. C) Spectral Signatures: A target's spectral fingerprint As mentioned before, remote sensing is based on the measurement of reflected (or emitted) radiation from different targets. Objects having different surface features reflect or absorb the sun's radiation in different ways. In order to understand and interprete the information extracted from remotely sensed data, you have to first understand the behavior of the target in respect to the electromagnetic spectrum. Each target will show a distinct reflectance pattern as a function of the wavelength - known as spectral signature (or a spectral fingerprint). This signature will directly (or indirectly) lead to the identification of a target based on its set of values for its reflectance in different spectral ranges: Figure 1.4: Typical spectral signatures of specic land cover types in the visible and infrared region of the electromagnetic spectrum (Source: http://www.seos-project.eu/) Reflectance is the ratio of the amount of light leaving a target to the amount of light striking the target. It has no units. The spectral signature of healthy green vegetation has a small reflectance in the visible portion of the electromagnetic spectrum resulting from the pigments in plant leaves. Most of the light is being used in the photosynthesis process. However, the reflectance increases dramatically in the near infrared. The spectral signature of soil is much less variable. Its behavior is affected by soil moisture, texture, surface roughness and they are less dominant than the absorbance features present in vegetation. The water's spectral signature is characterized by a high absorption at near infrared wavelengths range and beyond. Because of this absorption property, water bodies as well as features containing water can easily be detected, located and delineated with remote sensing data. These differences make it possible to identify different earth surface features or materials by analysing their spectral reflectance patterns or spectral signatures. References Fischer, W. A., W.R. Hemphill and A. Kover. 1976. Progress in Remote Sensing. Photogrametria, Vol. 32, pp. 33-72 Lintz, J. and D. S. Simonett. 1976. Remote Sensing of Environment. Reading, MA: Addison-Wesley. 694 pp. Barrett, E. C. and C. F. Curtis. 1976. Introduction to Environmental Remote Sensing. New York: Macmillian, 472 pp. Colwell, R. N. 1966. Uses and Limitations of Multispectral Remote Sensing. In Proceedings of the Fourth Symposium on Remote Sensing of Environment. Ann Arbor: Institute of Science and Technology, University of Michigan, pp. 71-100. 1.1.2 Google Earth Engine API and Java Script 1.1.3 Exploring Image and Image Collection 1.2 Image Manipulation 1.2.1 Band Math and VI Calculation 1.2.2 Thresholds and Masks "],["part-2-advanced-google-earth-engine.html", "Chapter 2 Part 2 - Advanced Google Earth Engine 2.1 Advanced Image Manipulation: Pre-classification 2.2 Supervised Classification: Random Forest 2.3 Post-classification processing", " Chapter 2 Part 2 - Advanced Google Earth Engine 2.1 Advanced Image Manipulation: Pre-classification 2.1.1 Cloud and cloud shadow masking Section Snapshot at GEE This section demonstrates a way of masking clouds and cloud shadow pixels from Landsat 8/7 Surface Reflectance data based on file metadata. This function was created based on the documentation available for Landsat 8/7. Values for pixel bit and pixel band were found here. The cloud masking function is as follows: function maskL8sr(image) { // #Bits 3 and 5 are cloud shadow and cloud, respectively. var cloudShadowBitMask = ee.Number(2).pow(3).int(); var cloudsBitMask = ee.Number(2).pow(5).int(); // #Get the pixel QA band. var qa = image.select(&#39;pixel_qa&#39;); // #Both flags should be set to zero, indicating clear conditions. var mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0) .and(qa.bitwiseAnd(cloudsBitMask).eq(0)); // #Return the masked image, scaled to [0, 1]. return image.updateMask(mask).divide(10000).copyProperties(image, [&quot;system:time_start&quot;]); }; 2.1.2 Spectral indices 2.1.3 Compositing 2.2 Supervised Classification: Random Forest 2.2.1 Land-cover classification using Random Forest 2.2.2 Map-to-Map Change 2.3 Post-classification processing 2.3.1 Re-classification 2.3.2 Map spatial smoothing "],["part-3-country-specific-applications.html", "Chapter 3 PART 3 - Country-specific Applications 3.1 Liberia 3.2 Guinea", " Chapter 3 PART 3 - Country-specific Applications 3.1 Liberia 3.1.1 Class-by-class land cover mapping 3.1.2 Multi-class land cover mapping 3.1.3 Land cover to ecosystems: a map merging approach 3.2 Guinea 3.2.1 Mangrove mapping in Guinea, West Africa "]]
