<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Part 1 - Basics &amp; Fundamentals | Supervised Classification with Google Earth Engine</title>
  <meta name="description" content="Chapter 1 Part 1 - Basics &amp; Fundamentals | Supervised Classification with Google Earth Engine" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Part 1 - Basics &amp; Fundamentals | Supervised Classification with Google Earth Engine" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Part 1 - Basics &amp; Fundamentals | Supervised Classification with Google Earth Engine" />
  
  
  

<meta name="author" content="Celio Sousa (celio.h.resendedesousa@nasa.gov)" />


<meta name="date" content="2022-04-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="part-2-advanced-google-earth-engine.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Classification Tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction and overview</a></li>
<li class="chapter" data-level="1" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html"><i class="fa fa-check"></i><b>1</b> Part 1 - Basics &amp; Fundamentals</a><ul>
<li class="chapter" data-level="1.1" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html#programming-and-remote-sensing-basics"><i class="fa fa-check"></i><b>1.1</b> Programming and Remote Sensing Basics</a><ul>
<li class="chapter" data-level="1.1.1" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html#remote-sensing-language"><i class="fa fa-check"></i><b>1.1.1</b> Remote Sensing Language</a></li>
<li class="chapter" data-level="1.1.2" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html#google-earth-engines-application-programming-interface-api-and-java-script"><i class="fa fa-check"></i><b>1.1.2</b> Google Earth Engine's Application Programming Interface (API) and Java Script</a></li>
<li class="chapter" data-level="1.1.3" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html#exploring-image-and-image-collection"><i class="fa fa-check"></i><b>1.1.3</b> Exploring Image and Image Collection</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html#image-manipulation"><i class="fa fa-check"></i><b>1.2</b> Image Manipulation</a><ul>
<li class="chapter" data-level="1.2.1" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html#band-math-and-vi-calculation"><i class="fa fa-check"></i><b>1.2.1</b> Band Math and VI Calculation</a></li>
<li class="chapter" data-level="1.2.2" data-path="part-1-basics-fundamentals.html"><a href="part-1-basics-fundamentals.html#thresholds-and-masks"><i class="fa fa-check"></i><b>1.2.2</b> Thresholds and Masks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html"><i class="fa fa-check"></i><b>2</b> Part 2 - Advanced Google Earth Engine</a><ul>
<li class="chapter" data-level="2.1" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#advanced-image-manipulation-pre-classification"><i class="fa fa-check"></i><b>2.1</b> Advanced Image Manipulation: Pre-classification</a><ul>
<li class="chapter" data-level="2.1.1" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#cloud-and-cloud-shadow-masking"><i class="fa fa-check"></i><b>2.1.1</b> Cloud and cloud shadow masking</a></li>
<li class="chapter" data-level="2.1.2" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#spectral-indices"><i class="fa fa-check"></i><b>2.1.2</b> Spectral indices</a></li>
<li class="chapter" data-level="2.1.3" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#compositing"><i class="fa fa-check"></i><b>2.1.3</b> Compositing</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#supervised-classification-random-forest"><i class="fa fa-check"></i><b>2.2</b> Supervised Classification: Random Forest</a><ul>
<li class="chapter" data-level="2.2.1" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#land-cover-classification-using-random-forest"><i class="fa fa-check"></i><b>2.2.1</b> Land-cover classification using Random Forest</a></li>
<li class="chapter" data-level="2.2.2" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#map-to-map-change"><i class="fa fa-check"></i><b>2.2.2</b> Map-to-Map Change</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#post-classification-processing"><i class="fa fa-check"></i><b>2.3</b> Post-classification processing</a><ul>
<li class="chapter" data-level="2.3.1" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#re-classification"><i class="fa fa-check"></i><b>2.3.1</b> Re-classification</a></li>
<li class="chapter" data-level="2.3.2" data-path="part-2-advanced-google-earth-engine.html"><a href="part-2-advanced-google-earth-engine.html#map-spatial-smoothing"><i class="fa fa-check"></i><b>2.3.2</b> Map spatial smoothing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="part-3-country-specific-applications.html"><a href="part-3-country-specific-applications.html"><i class="fa fa-check"></i><b>3</b> PART 3 - Country-specific Applications</a><ul>
<li class="chapter" data-level="3.1" data-path="part-3-country-specific-applications.html"><a href="part-3-country-specific-applications.html#liberia"><i class="fa fa-check"></i><b>3.1</b> Liberia</a><ul>
<li class="chapter" data-level="3.1.1" data-path="part-3-country-specific-applications.html"><a href="part-3-country-specific-applications.html#class-by-class-land-cover-mapping"><i class="fa fa-check"></i><b>3.1.1</b> Class-by-class land cover mapping</a></li>
<li class="chapter" data-level="3.1.2" data-path="part-3-country-specific-applications.html"><a href="part-3-country-specific-applications.html#multi-class-land-cover-mapping"><i class="fa fa-check"></i><b>3.1.2</b> Multi-class land cover mapping</a></li>
<li class="chapter" data-level="3.1.3" data-path="part-3-country-specific-applications.html"><a href="part-3-country-specific-applications.html#land-cover-to-ecosystems-a-map-merging-approach"><i class="fa fa-check"></i><b>3.1.3</b> Land cover to ecosystems: a map merging approach</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="part-3-country-specific-applications.html"><a href="part-3-country-specific-applications.html#guinea"><i class="fa fa-check"></i><b>3.2</b> Guinea</a><ul>
<li class="chapter" data-level="3.2.1" data-path="part-3-country-specific-applications.html"><a href="part-3-country-specific-applications.html#mangrove-mapping-in-guinea-west-africa"><i class="fa fa-check"></i><b>3.2.1</b> Mangrove mapping in Guinea, West Africa</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="part-4-ecosystem-accounting.html"><a href="part-4-ecosystem-accounting.html"><i class="fa fa-check"></i><b>4</b> Part 4 - Ecosystem Accounting</a><ul>
<li class="chapter" data-level="4.1" data-path="part-4-ecosystem-accounting.html"><a href="part-4-ecosystem-accounting.html#introduction-to-ecosystem-accounting"><i class="fa fa-check"></i><b>4.1</b> Introduction to Ecosystem Accounting</a><ul>
<li class="chapter" data-level="4.1.1" data-path="part-4-ecosystem-accounting.html"><a href="part-4-ecosystem-accounting.html#ecosystem-accounting"><i class="fa fa-check"></i><b>4.1.1</b> Ecosystem Accounting</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Supervised Classification with Google Earth Engine</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="part-1---basics-fundamentals" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Part 1 - Basics &amp; Fundamentals</h1>
<div id="programming-and-remote-sensing-basics" class="section level2">
<h2><span class="header-section-number">1.1</span> Programming and Remote Sensing Basics</h2>
<div id="remote-sensing-language" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Remote Sensing Language</h3>
<p><strong>A) Definition</strong></p>
<p>The term <em><strong>Remote sensing</strong></em> has been variously defined. Some of its early definitions include:</p>
<ul>
<li><p>[...] the art or science of telling something about an object without touching it .(Fischer et al., 1976)</p></li>
<li><p>Remote sensing is the acquisition of physical data of an object without touch or contact. (Lintz and Simonett, 1976)</p></li>
<li><p>Remote sensing is the observation of a target by a device separated from it by some distance. (Barrett and Curtis, 1976)</p></li>
<li><p>The term <em>remote sensing</em> in its broadest sense means &quot;reconnaissance at a distance.&quot; (Colwell, 1966)</p></li>
</ul>
<p>Thus, in the context of this training, we can define <em>Remote Sensing</em> as the science of acquiring information about a given target, object or phenomenon on the surface of the Earth by sensors on-board various platforms orbiting our planet.</p>
<p><strong>B) Building blocks of remote sensing</strong></p>
<p>Although the many different methods for collection, processing and interpretation of remotely sense data can vary widely, they will always have the following essential components:</p>
<div class="figure"><span id="fig:FigBuildingBlocks"></span>
<img src="images/BuildingBlocksRemoteSensing.png" alt="Basic components of a remote sensing system." width="1303" />
<p class="caption">
Figure 1.1: Basic components of a remote sensing system.
</p>
</div>
<ol style="list-style-type: upper-roman">
<li>Energy Source</li>
</ol>
<p>The source of the electromagnetic radiation/energy (EMR) is the first requirement of any remote sensing process. The electromagnetic spectrum is used to &quot;classify&quot; the EMR according to to its wavelength:</p>
<div class="figure"><span id="fig:FigEMS"></span>
<img src="images/EMS%20copy.png" alt="The Electromagnetic Spectrum" width="1105" />
<p class="caption">
Figure 1.2: The Electromagnetic Spectrum
</p>
</div>
<p>Depending on the source of energy they are using, the different remote sensing systems can be classified as <em><strong>active</strong></em> or <em><strong>passive</strong></em>. <em>Active</em> sensors will produce its own source of energy for the illumination of the target. They will emit the energy toward the target being investigated and the energy reflected by this target is detected and measured by the sensor. Usually, these sensors operate in the microwave range of the electromagnetic spectrum. On the other hand, <em>passive</em> sensors only measures the energy that is naturally available, usually from the sun. These sensors can only be used to detect the energy being reflected during the time when the sun is illuminating the Earth. These sensors usually measure energy from the optical range (visible, near infrared, short-wave infrared and thermal infrared).</p>
<div class="figure"><span id="fig:PassiveAndActive"></span>
<img src="images/PassiveAndActive.png" alt="Remote sensing can be classified as Passive or Active based on the source of energy." width="878" />
<p class="caption">
Figure 1.3: Remote sensing can be classified as Passive or Active based on the source of energy.
</p>
</div>
<p>You can also think about these concepts of <em>active</em> and <em>passive</em> using a handheld photogarphic camera as an example: When photographing a target in the dark, the camera flash will provide the energy necessary to illuminate the target. Therefore, in that case, the camera is an <em>active</em> sensor. On the other hand, this same camera will be a <em>passive</em> sensor when you are photographing a target or object during the day, when the target being illuminated by sun light and no flash is necessary.</p>
<ol start="2" style="list-style-type: upper-roman">
<li>Interaction with the target/object</li>
</ol>
<p>The most common medium in between the source and target is the atmosphere. This is where the firt interaction ocurrs. As the EMR travel from its source to the target, it will come in contact with and interact different atmosphere constituents: aerosols, water vapor, solid particles, ect. Secondly, once the EMR makes its way through the atmospherethe to the target, it will interact with it depending on the target properties and energy wavelength. The EMR can have different types of interaction when it encounters matter; whether it is gas, solid or gas: it can be <strong>transmitted</strong> (that is, it passes through the target), <strong>absorbed</strong> (that is, the target absorbs the energy usually increasing its temperature as a result), <strong>emitted</strong> (that is, energy is emitted from all matter at temperatures above the absolute zero of 0 Kelvins), <strong>scattered</strong> (that is, deflected in every direction) and <strong>reflected</strong> (that is, energy bounces off the target's surface and its direction is usually a function of target structure and texture).</p>
<div class="caution">
<p>
Keep in mind: All targets can show different proportions of each of these interactions.
</p>
</div>
<ol start="3" style="list-style-type: upper-roman">
<li>Recording of the energy by the sensor</li>
</ol>
<p>The sensor - often onboard of airplanes or satellites in space - will measure the returning EMR after it has interacted with the target and the atmosphere. This measurement is converted into a digital image with discrete values in units of digital number (DN) for each image pixel. Depending on the sensor, these resulting images will have different characteristiscs (or <em><strong>resolutions</strong></em>). They are:</p>
<ul>
<li><p><strong>Spatial Resolution</strong>: usually known as &quot;pixel size&quot;. It refers to the sensor's ability to discriminate different objects/targets. A higher spatial resolution means a smaller pixel size which, in turn, means that smaller objects can be distinguishable as separate targets.</p></li>
<li><p><strong>Spectral Resolution</strong>: Different sensors will measure the EMR at specific ranges (or wavelengths), usually called <em>bands</em>. Thus, the spectral resolution of a sensor usually refers to the number and bandwith of these bands.</p></li>
<li><p><strong>Radiometric Resolution</strong>: Usually measured in <em>bits</em>, it refers to the sensor's ability to detect the smallest change in the spectral reflectance among different targets. For example, a 8-bit image will have 256 levels of brightness while a 16-bit image has 65,536 levels of brightness.</p></li>
<li><p><strong>Temporal resolution</strong> (sensors onboard satellites): is the time required for the satellite to collect two images at the same geographic location on Earth. Higher temporal resolution means less time for revisiting the same location. However, temporal resolution is usually inverselly proportional to spatial resolution: The larger the pixel size, the larger area the sensor will cover which means less time until the next revisit.</p></li>
</ul>
<ol start="4" style="list-style-type: upper-roman">
<li>Transmission, Reception, and Processing</li>
</ol>
<p>The EMR recorded by the sensor is transmitted in an electronic form to a receiving station on Earth where the data is processed and stored.</p>
<ol start="22" style="list-style-type: upper-alpha">
<li>Analysis and Interpretation (we are here!)</li>
</ol>
<p>This is where this training is focused on! The EMR was transformed into a digital dataset where we can use specialized instruments/hardware/software to extract information about the target observed. This extraction is often done through <em><strong>image processing</strong></em> (or digital image processing), which is the process which makes an image interpretable for a given use. There are many methods of image processing, but these are the most common ones:</p>
<ul>
<li><p><strong>Image correction</strong>: The digital image recorded by the sensor on a satellite (or aircraft) may contain errors related to the geometry and brightness values of the pixels. For example, a geometrical correction, also called <em><strong>geo-referencing</strong></em>, is a procedure where the content of image will be assigned a spatial coordinate system (for example, geographical latitude and longitude).</p></li>
<li><p><strong>Image enhancement</strong>: This is related to modification of an image, by changing the pixel brightness values, to improve its visual aspects so that the actual analysis of images will be easier, faster and more reliable.</p></li>
<li><p><strong>Image classification</strong>: The overall goal of this method is to categorize all pixels in an image into themes (or <em><strong>land cover classes</strong></em>). This resulting map with its limited number of classes can be more readily and sucessfully interpreted compared to the raw image and it is often use for planning purposes. There are supervised and unsupervised methods for classification of an image: A <em><strong>supervised classification</strong></em> (human-guided) is based on the idea that a user can select sample pixels in an image that are representative of specific classes and then direct the image processing software to use these training sites as references for the classification of all other pixels in the image. These samples are selected based on the knowledge of the user. On the other hand, an <em><strong>unsupervised classification</strong></em> (computer/software-guided) is where the output classes are based on the software's ability to determine which pixels are related, using several different models and techniques.</p></li>
</ul>
<p>This final component of Remote Sensing (V) is achieved when we apply the extracted information to solve a particular problem.</p>
<p><strong>C) Spectral Signatures: A target's spectral fingerprint</strong></p>
<p>As mentioned before, remote sensing is based on the measurement of reflected (or emitted) radiation from different targets. Objects having different surface features reflect or absorb the sun's radiation in different ways. In order to understand and interprete the information extracted from remotely sensed data, you have to first understand the behavior of the target in respect to the electromagnetic spectrum. Each target will show a distinct reflectance pattern as a function of the wavelength - known as <em><strong>spectral signature</strong></em> (or a spectral fingerprint). This signature will directly (or indirectly) lead to the identification of a target based on its set of values for its reflectance in different spectral ranges:</p>
<div class="figure"><span id="fig:SpectralSignature"></span>
<img src="images/Spectral%20Signature.jpg" alt="Typical spectral signatures of specic land cover types in the visible and infrared region of the electromagnetic spectrum (Source: http://www.seos-project.eu/)" width="1642" />
<p class="caption">
Figure 1.4: Typical spectral signatures of specic land cover types in the visible and infrared region of the electromagnetic spectrum (Source: <a href="http://www.seos-project.eu/" class="uri">http://www.seos-project.eu/</a>)
</p>
</div>
<div class="rmdcomment">
<p>
<em><strong>Reflectance</strong></em> is the ratio of the amount of light leaving a target to the amount of light striking the target. It has no units.
</p>
</div>
<p>The spectral signature of <em>healthy green vegetation</em> has a small reflectance in the visible portion of the electromagnetic spectrum resulting from the pigments in plant leaves. Most of the light is being used in the photosynthesis process. However, the reflectance increases dramatically in the near infrared. The spectral signature of <em>soil</em> is much less variable. Its behavior is affected by soil moisture, texture, surface roughness and they are less dominant than the absorbance features present in vegetation. The <em>water</em>'s spectral signature is characterized by a high absorption at near infrared wavelengths range and beyond. Because of this absorption property, water bodies as well as features containing water can easily be detected, located and delineated with remote sensing data.</p>
<p>These differences make it possible to identify different earth surface features or materials by analysing their spectral reflectance patterns or spectral signatures. [add more text]</p>
<p><em><strong>References</strong></em></p>
<p>Fischer, W. A., W.R. Hemphill and A. Kover. 1976. Progress in Remote Sensing. <em>Photogrametria</em>, Vol. 32, pp. 33-72</p>
<p>Lintz, J. and D. S. Simonett. 1976. <em>Remote Sensing of Environment</em>. Reading, MA: Addison-Wesley. 694 pp.</p>
<p>Barrett, E. C. and C. F. Curtis. 1976. <em>Introduction to Environmental Remote Sensing</em>. New York: Macmillian, 472 pp.</p>
<p>Colwell, R. N. 1966. Uses and Limitations of Multispectral Remote Sensing. In <em>Proceedings of the Fourth Symposium on Remote Sensing of Environment</em>. Ann Arbor: Institute of Science and Technology, University of Michigan, pp. 71-100.</p>
</div>
<div id="google-earth-engines-application-programming-interface-api-and-java-script" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Google Earth Engine's Application Programming Interface (API) and Java Script</h3>
<p>Google Earth Engine is a cloud-based platform for scientific data analysis and remote sensing data processing. It provides a large catalog of ready-to-use, cloud-hosted datasets. One of Earth Engine's key features is the ability to handle computationally demading processing and analysis very fast by distributing them across a large number of servers. The ability to efficiently use the cloud-hosted datasets and computation is enabled by the Earth Engine API.</p>
<p>An API is a way to communicate with Google Earth Engine servers. It allows you to specify what computation or command you would like to do, and then to receive the results back from the servers. The API is designed so that users do not need to worry about how the computation is distributed across a cluster of machines and the results are assembled. Users of the API simply specify what needs to be done. This greatly simplifies the code by hiding the implementation detail from the users. It also makes Earth Engine simpler for users who are not too familiar with writing code.</p>
<p><strong>Java Script API and Introduction to the Code Editor</strong></p>
<p>The Earth Engine platform comes with a web-based Code Editor that allows you to start using the Earth Engine JavaScript API without any installation. It also provides additional functionality to display your results on a map, save your scripts, access documentation, manage tasks, and more. It has a one-click mechanism to share your code with other users—allowing for easy reproducibility and collaboration. In addition, the JavaScript API comes with a user interface library, which allows you to create charts and web-based applications with little effort.</p>
<p>The Code Editor is an integrated development environment for the Earth Engine JavaScript API. It offers an easy way to type, debug, run, and manage code. Once you have successfully registered for a Google Earth Engine account, you can visit <a href="https://code.earthengine.google.com/" class="uri">https://code.earthengine.google.com/</a> to open the Code Editor. When you first visit the Code Editor, you will see a screen such as the one shown below:</p>
<div class="figure"><span id="fig:CodeEditor"></span>
<img src="images/PartI-CodeEditor.PNG" alt="Earth Engine Code Editor" width="858" />
<p class="caption">
Figure 1.5: Earth Engine Code Editor
</p>
</div>
<p>The Code Editor allows you to type JavaScript code and execute it. When you are first learning a new language and getting used to a new programming environment, it is customary to make a program to display your name or the words “Hello World.” This is a fun way to start coding that shows you how to give input to the program and how to execute it. It also shows where the program displays the output. Doing this in JavaScript is quite simple. Copy the following code into the center panel:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="st">&#39;Hello World&#39;</span>);</code></pre></div>
<p>The line of code above uses the JavaScript <code>print()</code> function to print the text “Hello World” to the screen. Once you enter the code, click the <strong>Run</strong> button. The output will be displayed on the upper right-hand panel under the <strong>Console</strong> tab:</p>
<div class="figure"><span id="fig:PrintRun"></span>
<img src="images/PartI-PrintRun.png" alt="Running code with GEE" width="858" />
<p class="caption">
Figure 1.6: Running code with GEE
</p>
</div>
<p>You now know where to type your code, how to run it, and where to look for the output. You just wrote your first Earth Engine script and may want to save it. Click the <strong>Save</strong> button to save a script:</p>
<div class="figure"><span id="fig:Save"></span>
<img src="images/PartI-Save.png" alt="Saving a script" width="858" />
<p class="caption">
Figure 1.7: Saving a script
</p>
</div>
<div class="caution">
<p>
If this is your first time using the Code Editor, you will be prompted to create a home folder. This is a folder in the cloud where all your code will be saved. You can pick a name of your choice, but remember that it cannot be changed and will forever be associated with your account.
</p>
</div>
<p>Once youre home folder is created, you will be prompted to create a <em>new repository</em>. A repository is a like a folder where you can save your scripts. You can also share entire repositories with other users. Your account can have multiple repositories and each one can hold multiple code scripts. Start by creating a repository</p>
</div>
<div id="exploring-image-and-image-collection" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Exploring Image and Image Collection</h3>
</div>
</div>
<div id="image-manipulation" class="section level2">
<h2><span class="header-section-number">1.2</span> Image Manipulation</h2>
<div id="band-math-and-vi-calculation" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Band Math and VI Calculation</h3>
</div>
<div id="thresholds-and-masks" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Thresholds and Masks</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="part-2-advanced-google-earth-engine.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/celiosousa/LCMTutorial/edit/master/01-PART_I.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/celiosousa/LCMTutorial/blob/master/01-PART_I.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
