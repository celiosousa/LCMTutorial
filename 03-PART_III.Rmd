# PART 3 - Country-specific Applications

In this part we will explore examples of class-specific classification using previously used functions as well as useful land cover classification-based analysis.

## Guinea

Description of Guinea here

### Mangrove mapping in Guinea, West Africa

In this example, we will use the codes from the previous parts for mangrove mapping in Guinea, in West Africa. We will also introduce the use of other datasets for masking and sample selection to assist in the classification workflow.

We will start by [opening a new code editor page](https://code.earthengine.google.com/){target="_blank"} and
by defining the spatial and temporal parameters of the composite you wish to classify, just like the other examples. For the temporal parameters, let’s use an annual 2021 composite:

```{r eval=FALSE}
var year = 2021;
var startDay = (year)+'-01-01';
var endDay = (year)+'-12-30';
```

For the spatial parameters, we can use the *Large Scale International Boundary (LSIB)* dataset and select Guinea’s national border. First, we will load the dataset into an object  called 'countries' using the `ee.FeatureCollection()` object and the feature collection ID 'USDOS/LSIB/2013'. Secondly, we will filter the dataset using `.filterMetadata()` and select Guinea from the list of countries and storing it in `aoi`:

```{block, type='rmdcomment'}
Note that you can select a any country border by filtering *'USDOS/LSIB/2013'* dataset by using *.filterMetadata('name' , 'equals', 'NAME OF THE COUNTRY IN CAPITAL LETTERS')*. 
```

Alternatively, you can use any previously uploaded Guinea's boundary datasets available [here.](https://code.earthengine.google.com/16fbfeb335381c203fed98eb81712dda){target="_blank"} Select a dataset from the list, copy its Asset ID and load it with `ee.FeatureCollection` into `aoi`. 

```{r my-borders,  fig.cap="Examples of Guinea's administrative borders.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/borders.png")
```

In this example, we aim to map of Guinea's mangroves. Therefore, we will chose `prefecures5k` as it emcompasses the entirety of Guinea's coast:

```{r eval=FALSE}
var aoi = ee.FeatureCollection('users/capacityBuilding/Guinea/prefectures5k');
```

```{block, type='caution'}
*__Important__*: All these datasets were made available through our collaboration with our colleagues in Guinea and the World Bank and they were modified with a GIS software for the sole purpose of this exercise. You can upload any geographical dataset (both raster or shapefile) into GEE with the *__NEW__* button in the __Assets__ table. 
```

As auxiliary functions for cloud masking and spectral index calculation, we will use the same functions provided in PART 2:

```{r eval=FALSE}
function maskClouds(image) {
  var cloudShadowBitMask = ee.Number(2).pow(3).int();
  var cloudsBitMask = ee.Number(2).pow(4).int();
  var QA = image.select('QA_PIXEL');
  var mask = QA.bitwiseAnd(cloudShadowBitMask).eq(0)
      .and(QA.bitwiseAnd(cloudsBitMask).eq(0));
  return image.updateMask(mask).divide(100000).select("SR_B[0-9]*").copyProperties(image, ["system:time_start"]);
}

function addIndices(image) {
  var ndvi = image.normalizedDifference(['SR_B5','SR_B4']).rename('NDVI');
  var nbr = image.normalizedDifference(['SR_B5','SR_B7']).rename('NBR');
  var ndmi = image.normalizedDifference(['SR_B7','SR_B3']).rename('NDMI');
  var mndwi = image.normalizedDifference(['SR_B3','SR_B6']).rename('MNDWI');
  var sr = image.select('SR_B5').divide(image.select('SR_B4')).rename('SR');
  var bare = image.normalizedDifference(['SR_B6','SR_B7']).rename('BI');
  var gcvi = image.expression('(NIR/GREEN)-1',{
    'NIR':image.select('SR_B5'),
    'GREEN':image.select('SR_B3')
  }).rename('GCVI');
  var evi = image.expression(
  '2.5 * ((NIR-RED) / (NIR + 6 * RED - 7.5* SR_BLUE +1))', {
    'NIR':image.select('SR_B5'),
    'RED':image.select('SR_B4'),
    'SR_BLUE':image.select('SR_B2')
  }).rename('EVI');
  var msavi = image.expression(
  '(2 * NIR + 1 - sqrt(pow((2 * NIR + 1), 2) - 8 * (NIR - RED)) ) / 2', {
    'NIR': image.select('SR_B5'), 
    'RED': image.select('SR_B4')}
).rename('MSAVI');
    return image
    .addBands(ndvi)
    .addBands(nbr)
    .addBands(ndmi)
    .addBands(mndwi)
    .addBands(sr)
    .addBands(evi)
    .addBands(msavi)
    .addBands(gcvi)
    .addBands(bare);
}
```

__1) Masking__

In this example, we will focus on mangrove forest mapping. Therefore, other known classes can be masked from the analysis.  

```{r eval=FALSE}
var globalwater = ee.Image('JRC/GSW1_0/GlobalSurfaceWater');
```

The Global Water Dataset `'JRC/GSW1_0/GlobalSurfaceWater'` has different bands: one of them `'occurrence'`. This band shows how many times (expressed as %) a given pixel was classified as water relative to the total time span of the dataset. Let’s isolate the `'occurrence'` band from the globalwater object:

```{r eval=FALSE}
var occurrence = globalwater.select('occurrence');
```

__Masks__ are composed by zeros and non-zero values. When you set or apply a mask to an image, the output image will keep its original values where the mask has non-zero values and pixels will be masked where the mask has zeros:

```{r my-mask,  fig.cap="Masking procedure. In this figure, the mask was applied to the raster image generating an output image where pixels are visible only where the correspondent mask pixel has non-zero values.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/maskexample.png")
```

For this example, we want to create a water mask. Thus, the water mask has to have zeros where there is water and non-zero values for non-water pixels. Consequently, when we apply this mask to a Landsat image, pixels of water will be invisible (transparent) while all the other pixels will remain visible in the composite. For the mask using the JRC Global Water dataset, make sure you are selecting "permanent" water. One way of doing this is by filtering the dataset for water pixels that occurred more than 50% of the time over the 35 years time spam for this dataset. You can be more or less restrictive with the water extent by changing the 50% threshold.

```{r eval=FALSE}
var waterMask = occurrence.lt(50).unmask(1);
```

Note that `.lt(50)` was used to select pixels from `occurrence` that are __smaller__ (or lower) than 50%. Automatically, the values above 50% will be set to 0 which is what is needed for this mask. In this particular case, we use `.unmask(1)` to set to 1 (or unmask) all the other areas that were originally masked in the JRC Global Water dataset.

```{r my-watermask,  fig.cap="Global water mask produced with JRC’s Global Surface Water dataset and Guinea's coastal prefectures (`aoi`) in red for reference. You can add this mask to the map editor (and clip for `aoi`) using `Map.addLayer(waterMask.clip(aoi), {}, 'Water Mask')`. Areas in black (0) will be masked in the composite while areas in white (1) will remain.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/watermask.png")
```

- *__Elevation mask__*

The purpose of this mask is to further remove pixels that are unlikely to be mangrove forests based on altitude values. Generally, mangroves will occur near shore where elevation and slope are relatively low. Similar to the water mask, we will create a mask using the SRTM Elevation Data:

```{r eval=FALSE}
var srtm = ee.Image('USGS/SRTMGL1_003');
```

Similarly to the previous dataset, we will select the band of interest by using the `.select()` method. The altitude values for the SRTM dataset are stored in the elevation band  called 'elevation'. We will create a mask 'elevMask' where pixels that have elevation values *greater than 25 meters* are removed. For that, you select everything that is *__lower__* than (`.lte`) 25 meters; any other value above 25 meters will be set to 0 automatically when using `.select()`:

```{r eval=FALSE}
var elevation = srtm.select('elevation');
var elevMask = elevation.lte(25);
```

```{r my-elevmask,  fig.cap="Global elevation (> 25 m) mask produced with the Shuttle Radar Topography Mission dataset and Guinea's coastal prefectures (`aoi`) in red for reference. You can add this mask to the map editor (and clip for `aoi`) using *Map.addLayer(elevMask.clip(aoi), {}, 'Elevation Mask')*. Areas in black (0) will be masked in the composite while areas in white (1) will remain.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/elevmask.PNG")
```

[Code Checkpoint](https://code.earthengine.google.com/62a8bbb4bef12c7c998dd7fe665a6d66){target="_blank"}

__2) Landsat 8 Image Collection and Cloud-free Mosaic__

Similarly to the examples from PART 2, we will load the Landsat 8 Surface Reflectance data archive into an object called 'collection' by using the container `ee.ImageCollection()` and the collection ID `'LANDSAT/LC08/C02/T1_L2'`. Secondly, we will filter this image collection for the temporal parameters by using the method `.filterDate()`. Finally, we will map the cloud-masking and spectral indices functions to the collection:

```{r eval=FALSE}
var collection = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
                   .filterDate(startDay,endDay)
                   .map(maskClouds)
                   .map(addIndices);
```

Then, in an object called 'composite', we will reduce the image collection into an annual composite using the `.median()` method. Next, we will mask the composite using the masks `waterMask` and `elevMask` using `.mask()` method for the first mask and then `.updateMask()` for the second. This container is necessary as we are *__updating__* the raster that will have been masked by the first mask.  

```{r my-updatemask,  fig.cap="Output raster from .`mask()` and `.updateMask()` of a previously masked input raster. `.updateMask()` will only mask areas that have not been masked previously; if `.mask()` is used for a second mask, areas that have been previously invisible (i.e masked) will then assume the values of the mask used.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/updateMask.png")
```

```{block, type='rmdcomment'}
As a rule of thumb: the *first* mask applied to the raster is done by *.mask()* and then use *.updateMask()* for any subsequent masks.
```

Finally, we will clip the composite to our area of interest `aoi` using the container `.clip()` method:

```{r eval=FALSE}
var composite = collection
                .median()
                .mask(waterMask)
                .updateMask(elevMask)
                .clip(aoi);
```

```{block, type='starcomment'}
Setting your code with indents is very helpful!. It will allow you to "turn on" and "turn off" certain portions of a code with comment bars. In the example above, you can turn off any mask by just adding // before the full period.
```

```{r eval=FALSE}
var composite = collection
                .median()
                //.mask(waterMask)
                //.updateMask(elevMask)
                .clip(aoi);
```

```{block, type='starcomment'}
The code above is just for illustration purposes! Remember to remove the // from the portion of the code that you want Earth Engine to read.
```

Finally, add the composite to the Map editor using the code below.

```{r eval=FALSE}
Map.centerObject(aoi);
Map.addLayer(composite, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite');
```

This band composition (RGB 564) is a good composition to highlight mangrove forests:

```{r CompositeMaskedGuinea,  fig.cap="Masked composite displayed with an RGB564 composition highlighting mangrove forests in dark red. Notice that areas of open water and higher altitudes were masked as they are not relevant to our example. Unmasked composite was added for comparison purposes: you can take advantage of indenting to turn masks on/off with // comment bars.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-CompositeMaskedGuinea.png")
```

[Code Checkpoint](https://code.earthengine.google.com/912be20630ba0aa4c86d0d12b3d76f94){target="_blank"}

__3) Supervised Classification with Random Forest__

- *__Strata for Sample Selection__*

As shown in Part 1 and Part 2, the first step to perform a supervised classification is to select the training samples. One way of selecting the training samples for the Random Forest classifier was shown in the training sample selection section of Part 2. Alternatively, you can automatically select random points based on a stratification map using `.stratifiedSample()`. In this case, the stratification map will have two classes: Mangroves and Non-mangroves. You can create a mangrove stratum for sample selection using available mangrove datasets, such as:

- Global Mangrove Forest Distribution dataset (raster) for the year 2000, available through Google Earth Engine (`ee.ImageCollection('LANDSAT/MANGROVE_FORESTS')`), or;

- The latest global Mangrove Extent from the [Global Mangrove Watch](https://www.globalmangrovewatch.org/country/GIN?map=eyJiYXNlbWFwIjoibGlnaHQiLCJ2aWV3cG9ydCI6eyJsYXRpdHVkZSI6OS45NDcyMTU4OTUwNDI0NzIsImxvbmdpdHVkZSI6LTE1Ljk0Njk3MjgyMzgwNzMzOCwiem9vbSI6Ni4xMzk0MjcyMjU1NDAzMjcsImJlYXJpbmciOjAsInBpdGNoIjowfX0%3D){target="_blank"}, available for download [here.](https://data.unep-wcmc.org/datasets/45){target="_blank"}

- Or any other dataset that you may have available;

a) *Mangroves*: For this example, we will use the GMW Global mangrove extent dataset for 2016 that was previously downloaded and added as an asset to Google Earth Engine. First, load the mangrove extent shapefile into a `ee.FeatureCollection` object:

```{r eval=FALSE}
var mangroveDataset = ee.FeatureCollection('users/capacityBuilding/Guinea/Mangroves2016');
```

As seen in Part 2, to create the mangrove stratification class, we simply create an image with `ee.Image(1)` and clip it using `mangroveDataset`:

```{r eval = FALSE}
var mangrove = ee.Image(1).clip(mangroveDataset);
```

b) *Non-mangroves*: Using `.where()` (See its formula here: \@ref(fig:my-where)), we will create an image of zeros where the value two (2) will be added where there is a pixel of any band from the `composite`:

```{r eval = FALSE}
var nonmangrove = ee.Image(0).where(composite.select('SR_B1'),2).selfMask();
```

```{block, type='starcomment'}
Notice that a new method was used in the code above. The method `.selfMask()` is an method from an `ee.Image()` object that is used when you want to mask an image with itself. In other words, when an ee.Image has zeros in it, you can use `.selfMask()` to remove the zeros, just like an other mask.
```

Finally, to create a stratification classes map called 'strata', we will use `.where()` to set `nonmangrove` pixels to *1* where it overlaps with pixels of the mangrove stratum (`mangrove`) and use `.rename()` to rename it to `'stratificationClass'`:

```{r eval = FALSE}
var strata = nonmangrove.where(mangrove,1).rename('stratificationClass');
```

The object `strata` is an image with one band called `'stratificationClass'`, with Mangrove pixes have value of 1 and non-mangrove pixels have value of 2. It is good practice to rename this band to something easy to remember because `.stratifiedSample()` requires the image and the band name with which the samples will be selected.

Add `strata` to the map editor to visualize:

```{r eval = FALSE}
Map.addLayer (strata, {palette:['#6D8B74','#D0C9C0'], min:1, max:2}, 'Stratification Map');
```

```{r my-strata,  fig.cap="Stratification map `strata` showing Global Mangrove Watch's 2016 Mangrove extent (`stratificationClass: 1`) and non-mangrove areas (`stratificationClass: 2`). The `.stratifiedSample()` method will generate a set of random points to each of these classes.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-StratificationMap.png")
```

- *__Random training sample selection__*

Now that we have the stratification map `strata` for mangroves and all other areas, we will use `.stratifiedSample()` method below to select 1000 points (`classPoints`) for each of the two classes (`classValues`):


```{r eval = FALSE}
var stratified = strata.addBands(ee.Image.pixelLonLat()).stratifiedSample({
      numPoints: 1,
      classBand: 'stratificationClass',
      scale: 30,
      region: aoi,
      classValues:[1,2],       
      classPoints:[1000,1000]  
    }).map(function(f) {       
       return f.setGeometry(ee.Geometry.Point([f.get('longitude'), f.get('latitude')]));
    });
```

The code above includes:

a) `.addBands(ee.Image.pixelLonLat())` to add a band to `strata` that will have the latitude and longitude for each pixel;

b) `numPoints` is the default number of points to sample in each class in `strata`. If `numPoints` is set to 2000, 1000 points will be selected for each of the two classes in `strata`. This, however, can be overridden for specific classes using the `classValues` and `classPoints` properties. In this case, these properties allow which classes you want to use from your stratification map and how many points for each of these classes you want to select.

c) `classBand: 'stratificationClass'` to define the band from `strata` that will be used to select the random samples;

d) `scale` sets the scale to 30 meters to match Landsat nominal spatial resolution;

e) The rest of the code will set these samples as geometry and get their lat/long coordinates.

You can use the code below to colorize these point samples based on a color palette for visualization. First, the color pallete for this particular case will be slightly different that the color palettes that have been used throught this tutorial so far: it will be created as a `ee.List()` of colors including a null color:

```{r eval=FALSE}
var paletteSamples = ee.List([
  'FFFFFF',  // NULL
  '6D8B74',  // Mangrove
  'D0C9C0',  // Non-Mangrove
 ]);
```

Then, a 'features' object will be created to include the colorized version of `stratified` based on the code:

```{r eval=FALSE}
var features = stratified.map(function(f) {
  var landcover = f.get('stratificationClass');
  return ee.Feature(ee.Geometry.Point([f.get('longitude'), f.get('latitude')]), f.toDictionary()).set({style: {color: paletteSamples.get(landcover) }}); 
}); 
```

Finally, we will add `features` to the map editor using `Map.addLayer` and `.style()` following the formula below:

```{r eval = FALSE}
Map.addLayer(features.style({styleProperty: "style"}),{}, 'Samples/Location');
```

```{block, type='rmdcomment'}
Remember, __these steps are not necessary to the classification workflow__. However, it allows you to visualize the selected samples with a color palette of your choice.
```

```{r StratificationSamples,  fig.cap="Stratified random samples. The `.stratifiedSample()` method generates a set of random points to each of these strata.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-StratificationSamples.png")
```

[Code Checkpoint](https://code.earthengine.google.com/9eebb9a441f2e4e6cff74329e8aa9563){target="_blank"}

- *__Classification__*

As seen in in Part 2, one of the first steps to train a Random Forest classifier is select the predictors to assign to each sample point in the sample set. For this example, we will create a list ('bands') with the names of three spectral bands (`'SR_B4'`,`'SR_B5'`,`'SR_B6'`) and the spectral indices (`'NDVI'`,`'NBR'`,`'MNDWI'`,`'SR'`,`'GCVI'` and `'MSAVI'`).

```{r eval=FALSE}
var bands = ['SR_B4','SR_B5','SR_B6','NDVI','NBR','MNDWI','SR','GCVI','MSAVI'];
```


```{r eval=FALSE}
var samplesAutomatic = composite.select(bands).sampleRegions({
  collection: stratified,   
  properties: ['stratificationClass'],
  scale: 30,
  geometries: true,
});
```

A second sample set ('groundtruth') will be used to illusrate a validation process for the mangrove extent map. First, we will load a pre-selected set of samples using `ee.FeatureCollection()` then create 'samplesgroundtruth' similarly to the previous set of samples:

```{r eval=FALSE}
var groundtruth = ee.FeatureCollection('users/capacityBuilding/Guinea/Groundtruth');
```

If you print `groundtruth` to the __Console__ tab, you will see that its property is called `landcover`. Therefore, in the code below, the argument `properties` will be a 'landcover':

```{r eval=FALSE}
var samplesgroundtruth = composite.select(bands).sampleRegions({
  collection: groundtruth,
  properties: ['landcover'],
  scale: 30,
  geometries: true,
});
```

Next, we will train a Random Forest classifier using the `samplesAutomatic` as training samples. In this example, we will use 200 trees and 8 predictors tested at each tree node:

```{r eval=FALSE}
var RandomForest = ee.Classifier.smileRandomForest(200,8).train({
  features: samplesAutomatic, 
  classProperty: 'stratificationClass', 
  inputProperties: bands
});
```

Finally, we will classify `composite` into a mangrove extent map using the trained classifier and add the output to the map editor using a color palette of your choice:

```{r eval=FALSE}
var classification = composite.select(bands).classify(RandomForest);

var paletteMAP = [
  '01937C', // Mangrove
  'B6C867', // Non-Mangrove
];

Map.addLayer (classification, {min: 1, max: 2, palette:paletteMAP}, 'Classification with Automatic Samples');
```

```{r my-classficationmangrove,  fig.cap="Random forest classification output produced with automatic sample selection", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-RFMangroveGuinea.png")
```

[Code Checkpoint](https://code.earthengine.google.com/0a0e15f94c78cb1516c90de46ec1fe10){target="_blank"}

- *__Validation__*

For the validation of the mangrove extent map we will use `.classify()` and `.errorMatrix()`.The `.classify` method will classify the ground truth samples with the trained random forest classifier; `.errorMatrix()` will compare the result of this classification with their own class label: 

```{r eval=FALSE}
var validation = samplesgroundtruth.classify(RandomForest);
var testAccuracy = validation.errorMatrix('landcover', 'classification');
```

Print the results to the __Console__:

```{r eval=FALSE}
print('Map Overall Accuracy: ', testAccuracy.accuracy());
print('Kappa: ', testAccuracy.kappa());
print('Validation error matrix Map: ', testAccuracy);
```

```{r ValidationGuinea,  fig.cap="Validation results for this example. Ground truth data (in this context it refers to independent samples) were used to calculate the overall accuracy and kappa values.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-ValidationGuinea.png")
```

## Liberia

In this example, we will use the codes from the previous sections for a class by class land cover mapping in Liberia, in West Africa. We will also take advantage of other datasets for masking and sample selection to assist in the classification workflow.

### Class-by-class land cover mapping

We will start by [opening a new code editor page](https://code.earthengine.google.com/){target="_blank"} and
by defining the spatial and temporal parameters of the composite you wish to classify, just like the other examples. As explained in Part 1, GEE’s cloud screening algorithm based on quality assessment bands (QA) can be applied to remove cloud and cloud shadow contaminated pixels for each of the Landsat scene covering y. This method greatly improves the final composite (See \@ref(fig:CompositesMasked)). However, creating an annual *completely cloud-free* imagery composition for Liberia is a challenging task because of the west African monsoon, which causes constant clouds across the Gulf of Guinea most of the time. The rainy season in Liberia ranges from May to October and it frequently rains in other months, except in the short dry season that runs from December to February/March. Hence, __multi-year composites are necessary in attaining wall-to-wall cloud-free mosaics over Liberia__. 

In order to ensure that an adequate cloud-free composite is achieved, we will use a composite circa 2021-2022. Then the temporal parameters can be defined as:

```{r eval=FALSE}
var year = 2021;
var startDay = (year)+'-01-01';
var endDay = (year+1)+'-05-30';
```

Note that this time range will include all available Landsat 8 Surface Reflectance images from January 2021 through May 2022 (`year+1`).

For the spatial parameters, we can use the *Large Scale International Boundary (LSIB)* dataset and select Liberia’s national border. First, we will load the dataset into an object called 'countries' using the `ee.FeatureCollection()` object and the feature collection ID 'USDOS/LSIB/2013'. Secondly, we will filter the dataset using `.filterMetadata()` and select Liberia from the list of countries and storing it in `nationalBorder`:

```{block, type='rmdcomment'}
Note that you can select a any country border by filtering *'USDOS/LSIB/2013'* dataset by using *.filterMetadata('name' , 'equals', 'NAME OF THE COUNTRY IN CAPITAL LETTERS')*. 
```

If you want to visualize your feature collection, you can add it to the map using the `Map.addLayer()`:

```{r eval=FALSE}
var countries = ee.FeatureCollection('USDOS/LSIB/2013');
var nationalBorder = countries.filterMetadata('name' , 'equals', 'LIBERIA');
Map.centerObject(nationalBorder);
Map.addLayer(nationalBorder, {color: 'Blue'}, 'Liberia National Borders');
```

```{r LiberiaBorder,  fig.cap="Liberia border extracted from the *Large Scale International Boundary (LSIB)* dataset.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-LiberiaBorder.png")
```

Alternatively, you can import your own border shapefile to your assets using the __NEW__ button in the __Assets__ tab. (See Earth Engine's [Importing Raster Data](https://developers.google.com/earth-engine/guides/image_upload){target="_blank"} for instructions on uploading an image to your assets or [Importing Table/Shapefile Data](https://developers.google.com/earth-engine/guides/table_upload){target="_blank"} for more details).

In this example, we imported a shapefile containing all of Liberia's counties to our assets:

```{r ImportingShapefile,  fig.cap="Importing shapefiles to your assets.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-ImportingShapefile.png")
```

Once the upload is completed, the imported dataset can be accessed in the __Assets__ tab. We will import it to the script using its 'ID' and add to the map editor: 

```{r eval=FALSE}
var aoi = ee.FeatureCollection('users/capacityBuilding/Liberia/LiberiaCounties');
Map.addLayer(aoi, {color: 'red'}, 'LiberiaCounties');
```

```{r Counties,  fig.cap="`aoi` and its multiple features (counties)", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-Counties.png")
```

In this particular case, this dataset includes multiple features (or polygons) with several properties for each feature. One of them is called 'NAME_1', which includes the names of each county in Liberia: 

```{r AssetDetail,  fig.cap="Asset information. This imported dataset includes multiple features.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-AssetDetail.png")
```

You can also print `aoi` to the __Console__ tab:

```{r eval=FALSE}
print(aoi);
```

```{r FCProperties,  fig.cap="Feature collection information printed to the console. This imported dataset includes multiple features.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-FCProperties.png")
```

This type of metadata can be used to filter a feature collection. The `ee.Filter.inList()` method is very helpful when you want to filter multiple properties at once. First, we will create an object called 'filterCounties' with a list of 4 of the 15 counties in Liberia. In this example, we selected the counties of Bomi, Montserrado, Margibi and Grand Bassa. Finally, we use `filter()` to filter `aoi` for the list of counties provided in `filterCounties`:

```{r eval=FALSE}
var filterCounties = ee.Filter.inList('NAME_1', ['Bomi', 'Montserrado','Margibi','GrandBassa']);
var filteredAOI = aoi.filter(filterCounties);
Map.addLayer(filteredAOI, {color: 'green'}, 'filteredArea');
```

```{r FilteredCounties,  fig.cap="The `aoi` feature collection filtered by metadata. Here, a filter to select the counties of Bomi, Montserrado, Margibi and Grand Bassa was used. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-FilteredCounties.png")
```

Now that both temporal and spatial parameters are defined, As auxiliary functions for cloud masking and spectral index calculation, we will use the same functions provided in PART 2:

```{r eval=FALSE}
function maskClouds(image) {
  var cloudShadowBitMask = ee.Number(2).pow(3).int();
  var cloudsBitMask = ee.Number(2).pow(4).int();
  var QA = image.select('QA_PIXEL');
  var mask = QA.bitwiseAnd(cloudShadowBitMask).eq(0)
      .and(QA.bitwiseAnd(cloudsBitMask).eq(0));
  return image.updateMask(mask).divide(100000).select("SR_B[0-9]*").copyProperties(image, ["system:time_start"]);
}

function addIndices(image) {
  var ndvi = image.normalizedDifference(['SR_B5','SR_B4']).rename('NDVI');
  var nbr = image.normalizedDifference(['SR_B5','SR_B7']).rename('NBR');
  var ndmi = image.normalizedDifference(['SR_B7','SR_B3']).rename('NDMI');
  var mndwi = image.normalizedDifference(['SR_B3','SR_B6']).rename('MNDWI');
  var sr = image.select('SR_B5').divide(image.select('SR_B4')).rename('SR');
  var bare = image.normalizedDifference(['SR_B6','SR_B7']).rename('BI');
  var gcvi = image.expression('(NIR/GREEN)-1',{
    'NIR':image.select('SR_B5'),
    'GREEN':image.select('SR_B3')
  }).rename('GCVI');
  var evi = image.expression(
  '2.5 * ((NIR-RED) / (NIR + 6 * RED - 7.5* SR_BLUE +1))', {
    'NIR':image.select('SR_B5'),
    'RED':image.select('SR_B4'),
    'SR_BLUE':image.select('SR_B2')
  }).rename('EVI');
  var msavi = image.expression(
  '(2 * NIR + 1 - sqrt(pow((2 * NIR + 1), 2) - 8 * (NIR - RED)) ) / 2', {
    'NIR': image.select('SR_B5'), 
    'RED': image.select('SR_B4')}
).rename('MSAVI');
    return image
    .addBands(ndvi)
    .addBands(nbr)
    .addBands(ndmi)
    .addBands(mndwi)
    .addBands(sr)
    .addBands(evi)
    .addBands(msavi)
    .addBands(gcvi)
    .addBands(bare);
}
```

__1) Landsat 8 Image Collection and Cloud-free Mosaic__

Similarly to the examples from PART 2 and PART 3.1, we will load the Landsat 8 Surface Reflectance data archive into an object called 'collection' by using the container `ee.ImageCollection()` and the collection ID `'LANDSAT/LC08/C02/T1_L2'`. Secondly, we will filter this image collection for the temporal parameters by using the method `.filterDate()`. Finally, we will map the cloud-masking and spectral indices functions to the collection:

```{r eval=FALSE}
var collection = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')
                   .filterDate(startDay,endDay)
                   .map(maskClouds)
                   .map(addIndices);
```

Then, in an object called 'composite', we will reduce the image collection into a 2021/2022 composite using the `.median()` method. Finally, we will clip the composite to our area of interest `filteredAOI` using the container `.clip()` method:

```{r eval=FALSE}
var composite = collection
                .median()
                .clip(filteredAOI);
```

We will add `composite` to the Map editor:

```{r eval=FALSE}
Map.addLayer(composite, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite',false);
```

```{r LiberiaComposite,  fig.cap="A RGB564 composition of `composite`. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-LiberiaComposite.png")
```

Finally, we can export this composite as an asset. This will save you some time in the next steps where we will be using this same composite for classifying multiple land cover. For this example, we will use the `Export.image.toAsset()` as follows:

```{r eval=FALSE}
Export.image.toAsset({
  image: composite,
  description: 'CompositeLiberia2021',
  assetId: 'CompositeLiberia2021',
  crs:'EPSG:4326',
  crsTransform:[0.0002777777777777778,0,-180.0001388888889,0,-0.0002777777777777778,60.00013888888889],
  maxPixels:1e13,
  });
```

The code above will export the `composite` to your asset folder using the coordinate reference system (crs) and its affine. This is a necessary step to avoid a 15 meter pixel shift when using the default export parameters. Choose your folder and your asset ID anc click run:

```{r PartIII-CompositeExport,  fig.cap="Exporting the composite as an asset. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-CompositeExport.png")
```

[Code Checkpoint](https://code.earthengine.google.com/714db6d9b8c8d00fd4473ac627b7cf3b){target="_blank"}

__2) Classification: Class-by-class__

A class-by-class classification approach will follow the steps depicted in the figure below:

```{r ClassificationApproach,  fig.cap="A class by class classification approach. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-ClassByClassApproach.png")
```

So, far we have covered a multi-class classification approach. This is the most common way to perform a classification of multiple classes: feed the classifier all the samples from the different classes and post-process the outputs.
However, we can include a pre-classification step to isolate the class of interest and then perform the classification for that particular land cover. Later, we will mask this class from the composite in order to exclude those pixels from the classification process and potentially avoid comission and omission errors. Why is this relevant/important? - Answer: Pixel-based classification may generate a large number of misclassified pixels (the "salt-and-pepper effect") due to the spectral diversity within the same land cover type and spectral confusion between land cover types.
For that, a spectral signature analysis can be performed for identifying potential spectral bands and reflectance-based spectral indices thresholds for differentiating between two classes: the land cover class being mapped and the remaining land cover classes merged as a single class called “Other”.

__*Water bodies*__

Water bodies are usually the easiest class to start with. Not many other land cover classes will have a similar spectral signature. Therefore, it is good practice to start with classes that are easily classifiable.
As mentioned previously, we will use a pre-classification step to isolate the class of interest and then perform the classification for that particular land cover. We can do that by using a Masking Phase (Se Figure \@ref(fig:ClassificationApproach)). In this phase, we use a band/ index threshold analysis to create a mask that will remove most pixels that are unlikely to be the class of interest - in this particular case, water bodies.
In this example we will use the Modified Normalized Difference Water Index (MNDWI) that was calculated and added as a separate band to the `composite` using the `addIndices` function. This index will usually have mostly positive values for wet areas and negative values for other land cover classes.
Therefore we can creat a 'wetMask' using a value thresold:

```{r eval=FALSE}
var wetMask = composite.select('MNDWI').gte(-0.1).clip(filteredAOI);
```

The code above is selecting the pixels from the band "MNDWI" from `composite` that has values that are equal or greater than -0.1. Automatically, `wetMask` will be an image of ones (1) where the pixels meet the criteria above (MNDWI values greater than -0.1) and zeros (0) everywhere else. You can add `wetMask` to the map to check how constrictive your threshold values are:

``` {r eval=FALSE}
Map.addLayer(wetMask.selfMask(), {palette:'blue'}, 'WetMask');
```

```{r PartIII-Watermask,  fig.cap="A mask created based on the MNDWI values that are equal or greater than -0.1. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-Watermask.png")
```

Note that this mask includes all the water pixels (in black as seen in the RGB 564 color composition) plus other areas that area not open water bodies but include some level of wetness to them (usually mangroves and wetlands). The objective of this phase *__IS NOT__* to remove *__ALL__* pixels that are not water; rather, is to remove *__MOST__* pixels that are not water. You can think of this as a classification process that preceeds the actual random forest classification. Instead of having to classify the entire composite into two classes, this way you can reduce the number of pixels going into the Random Forest Classification, speeding up the process. Also, this process already eliminated pixels that are unlikely to be water, reducing even further the chances of missclassification.

We will use this mask to mask `composite`:

``` {r eval=FALSE}
var compositemasked = composite.mask(wetMask);
Map.addLayer(compositemasked, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite Masked');
```

```{r PartIII-MaskedComposite,  fig.cap="`composite` masked using `wetMask`. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-MaskedComposite.png")
```

This is the resulting Landsat composite that will be used in this first classification iteration! The next steps should be familiar to you:
* Selecting training samples - here we will create the two geometries to hold the 'water' and 'other' samples. Remember to set a property called 'landcover':

```{r PartIII-WaterSamples,  fig.cap=" Geometry imports to hold the training samples. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-WaterSamples.png")
```

[Code Checkpoint](https://code.earthengine.google.com/4a32727cbaefeb2d4f60037073884618){target="_blank"}

* Training a random forest classifier:

``` {r eval=FALSE}
var classes = Water.merge(Other);
var bands = ['SR_B4','SR_B5','SR_B6','NDVI','NBR','MNDWI','SR','GCVI','MSAVI'];

var samples = compositemasked.select(bands).sampleRegions({
  collection: classes,       
  properties: ['landcover'],
  scale: 30                  
}).randomColumn('random');

var split = 0.8;
var training = samples.filter(ee.Filter.lt('random', split));
var testing = samples.filter(ee.Filter.gte('random', split));

print('Samples n =', samples.aggregate_count('landcover'));
print('Training n =', training.aggregate_count('landcover'));
print('Testing n =', testing.aggregate_count('landcover'));

var classifier = ee.Classifier.smileRandomForest(100,5).train({
  features: training,
  classProperty: 'landcover', 
  inputProperties: bands
});

var validation = testing.classify(classifier);
var testAccuracy = validation.errorMatrix('landcover', 'classification');

print('Validation error matrix RF: ', testAccuracy);
print('Validation overall accuracy RF in %: ', testAccuracy.accuracy().multiply(100));
```

* Classifying `compositemasked` into 'Water' and 'Others'.

```{r eval=FALSE}
var classification = compositemasked.select(bands).classify(classifier);

var paletteMAP = [
  '#35ff17',  // Other (Class value 0)
  '#1c48d6',  // Water (Class value 1)
];

Map.addLayer (classification, {min: 0, max: 1, palette:paletteMAP}, 'Classification');
```

You should get something similar to this:

```{r PartIII-WaterClass,  fig.cap=" Classification output. ", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-WaterClass.png")
```

Finally, we will save this output to our Assets folder using the `Export.image.toAsset()`:

```{r eval=FALSE}
Export.image.toAsset({
  image: classification,
  description: 'WaterClassification',
  assetId: '1-Water',
  crs:'EPSG:4326',
  crsTransform:[0.0002777777777777778,0,-180.0001388888889,0,-0.0002777777777777778,60.00013888888889],
  maxPixels:1e13,
  });
```

This export may take several minutes. This asset will be used in the next classification to mask the composite for this class!

[Code Checkpoint](https://code.earthengine.google.com/8487823c78141fce13374e5c060902e0){target="_blank"}

__*Mangroves*__

Congratulations! You have classified your first land cover class! Next on the list is 'Mangroves'. This one is fairly straighforward to classify as this type of vegetation will have traces of the water spectral signature. We can use a similar index threshold approach for this class. Adittionally, we can use other datasets to mask other pixels that are unlikely to be Mangroves, such as elevation (Please refer to the Guinea section of this chapter for more information).

First, we will open a [new Code Editor page](https://code.earthengine.google.com/){target="_blank"} and import the Landsat composite, the feature collection of Liberia counties and the water classification:

```{r eval=FALSE}
var composite = ee.Image('users/capacityBuilding/Liberia/CompositeLiberia2021');
var aoi = ee.FeatureCollection('users/capacityBuilding/Liberia/LiberiaCounties');
var filterCounties = ee.Filter.inList('NAME_1', ['Bomi', 'Montserrado','Margibi','GrandBassa']);
var filteredAOI = aoi.filter(filterCounties);
var waterClass = ee.Image('users/capacityBuilding/Liberia/1-Water');
Map.addLayer(composite, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite');
```

In this step, we will create three masks: one based the class we already have (water class),one based on elevation (mangroves tend to ocurr in flat areas near the shore. Thus an elevation cut off can be use to eliminate most of other pixels) and, finally, one based on spectral threshold (similarly to what we have done in the previous step). The resulting composite will be what we will use for classifying Mangroves:

A) Mask I - Water Class

Here, we will create a mask based on the water classification. For that, we will create a `ee.Image` populate it with 1 and where it overlaps with the water class, populate it with 0. This way, when we apply this mask to the `composite`, the classified water pixels will be masked, leaving only the other pixels available for classification:

```{r eval = FALSE}
var waterMask = ee.Image(1). where(waterClass.select(['classification']).eq(1),0).clip(filteredAOI);
Map.addLayer(waterMask.selfMask(), {palette:['yellow']}, 'Water Mask');
```

Note that the value provided within `eq()` needs to match the value of your class.

B) Mask II - Elevation (See \@ref(fig:my-elevmask))

For the elevation mask, we will take advantage of the Shuttle Radar Topography Mission's elevation data available on GEE. We will use an elevation cut off of 25 meters: the composite will be masked where pixels have values > 25 m of elevation: 

```{r eval=FALSE}
var elevation = ee.Image('USGS/SRTMGL1_003').select('elevation');
var elevationMask = elevation.lte(25).clip(filteredAOI);
Map.addLayer(elevationMask.selfMask(), {palette:['pink']}, 'Elevation Mask');
```

C) Mask III - Index Threshold
For the threshold mask, we will use the same index we used in the Water classification masking phase:

```{r eval=FALSE}
var wetMask = composite.select('MNDWI').gte(-0.12);
Map.addLayer(wetMask.selfMask(), {palette:['blue']}, 'Wet Mask');
```

These are the three masks that will be applied to `composite`:

```{r PartIII-MASKS,  fig.cap= "When applying these three masks to the composite, pixels will only remain where the three masks overlap.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-MASKS.png")
```

Finally, we will apply these masks to the `composite` using `.mask()` for the first mask and `.updateMask()` for the others:
```{r eval=FALSE}
var compositemasked = composite.mask(waterMask)
                               .updateMask(elevationMask)
                               .updateMask(wetMask);

Map.addLayer(compositemasked, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite Masked');
```

You should achieve something like this:

```{r PartIII-CompositeMaskedII,  fig.cap= "Masked composite.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-CompositeMaskedII.png")
```

Next, we will repeat the sampling selection and classification. As a tip for selection accurate samples, mangroves will be in a darker shade of red/orange in this RGB 564 color composition while other vegetative classes (e.g. evergreen forests) will have a lighter red/orange shade. Make sure to take advantage of the high resolution imagery using the __Satellite__ button:

```{r PartIII-Mangrove,  fig.cap= "Mangroves and other vegetation classes in Liberia.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-Mangrove.png")
```

```{r eval=FALSE}
var classes = Mangrove.merge(Other);
var bands = ['SR_B4','SR_B5','SR_B6','NDVI','NBR','MNDWI','SR','GCVI','MSAVI'];

var samples = compositemasked.select(bands).sampleRegions({
  collection: classes,       
  properties: ['landcover'],
  scale: 30                  
}).randomColumn('random');

var split = 0.8;
var training = samples.filter(ee.Filter.lt('random', split));
var testing = samples.filter(ee.Filter.gte('random', split));

print('Samples n =', samples.aggregate_count('landcover'));
print('Training n =', training.aggregate_count('landcover'));
print('Testing n =', testing.aggregate_count('landcover'));

var classifier = ee.Classifier.smileRandomForest(100,5).train({
  features: training,
  classProperty: 'landcover', 
  inputProperties: bands
});

var validation = testing.classify(classifier);
var testAccuracy = validation.errorMatrix('landcover', 'classification');

print('Validation error matrix RF: ', testAccuracy);
print('Validation overall accuracy RF in %: ', testAccuracy.accuracy().multiply(100));

var classification = compositemasked.select(bands).classify(classifier);

var paletteMAP = [
  '#35ff17',  // Other (Class value 0)
  '#ce0dd6',  // Mangroves (Class value 1)
];

Map.addLayer (classification, {min: 0, max: 1, palette:paletteMAP}, 'Classification');
```

```{r PartIII-Mangroves,  fig.cap= "Classification output.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-Mangroves.png")
```

Finally, we will export the classification:

```{r eval=FALSE}
Export.image.toAsset({
  image: classification,
  description: 'MangroveClassification',
  assetId: '2-Mangroves',
  crs:'EPSG:4326',
  crsTransform:[0.0002777777777777778,0,-180.0001388888889,0,-0.0002777777777777778,60.00013888888889],
  maxPixels:1e13,
  });
```

[Code Checkpoint](https://code.earthengine.google.com/91448c680e2b1a24414c6f97984edf1d){target="_blank"}

__*Settlements*__

Now, we are moving into classes that require not only a spectral analysis but also a contextual one to be accurately classified. A good example is the artificial surfaces/ settlements class. In the case of Liberia, these areas will have very similar spectral behavior as exposed soil and bare areas, as most of the villages and small towns are usually located within these land cover classes. Therefore, a contextual evaluation needs to be included to ensure that bare areas are not being missclassified as settlements. In this case, we can use datasets like the location of these settlements and population density. These are extra pieces of information that we can use to constrain the classification to the correct area. In this example, we will use the [Liberia census population dataset from 2007-2008](https://energydata.info/dataset/liberia-populated-settlements){target="_blank"} created by Liberia Institute of Statistics and Geo-Information Services (LISGIS). The dataset contains a list of all the settlements that are geo-located and have attributes with their administrative units and population data (total, male, female and number of households). 
Additionally, we can use the Global Population Density dataset to further refine our classification.

Similarly to the last classification, we will open a [new Code Editor page](https://code.earthengine.google.com/){target="_blank"} and import the Landsat composite, the feature collection of Liberia counties, the feature collection of Liberia settlements, the global population density dataset (available through GEE) and the water and mangrove classification outputs:

```{r eval= FALSE}
var composite = ee.Image('users/capacityBuilding/Liberia/CompositeLiberia2021');
var aoi = ee.FeatureCollection('users/capacityBuilding/Liberia/LiberiaCounties');
var filterCounties = ee.Filter.inList('NAME_1', ['Bomi', 'Montserrado','Margibi','GrandBassa']);
var filteredAOI = aoi.filter(filterCounties);

var settlements = ee.FeatureCollection('users/capacityBuilding/Liberia/PopulatedSettlements2007');
var PopulationCount = ee.Image('JRC/GHSL/P2016/POP_GPW_GLOBE_V1/2015');

var waterClass = ee.Image('users/capacityBuilding/Liberia/1-Water');
var mangroveClass = ee.Image('users/capacityBuilding/Liberia/2-Mangroves');
```

You can add these layers to the Map Editor for inspection:

```{r eval=FALSE}
Map.addLayer(composite, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite');
Map.addLayer(PopulationCount.clip(filteredAOI), {palette:["ffffe7","FFc869","ffac1d","e17735","f2552c","9f0c21"], min:0, max:500}, 'Population Count');
Map.addLayer(settlements, {}, 'Settlements');
```

```{r PartIII-Pop,  fig.cap= "Ancillary datasets for classification of human settlements in Liberia. The population density and small settlement locations is helpful to constrain the classification in certain areas and help reduce misclassification errors with spectrally similar classes such as bare soil.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-Pop.png")
```

Similarly to the previous classification, we will create the masks based on these datasets to apply to the composite:

A) Mask I - Water and Mangrove class masks

```{r eval=FALSE}
var waterMask = ee.Image(1). where(waterClass.select(['classification']).eq(1),0).clip(filteredAOI);
var mangroveMask = ee.Image(1). where(mangroveClass.select(['classification']).eq(1),0).clip(filteredAOI);
```

B) Mask II - Population Masks

In this particular case, we are using two different datasets: one is an `ee.Image()` (`PopulationCount`) and the other is a `ee.FeatureCollection()` (`settlements`). Fot that we will create two different masks and merge them together as a single mask. First, we will create a population count mask based on the number of people per pixel. Using the same construction as before, we will create a `ee.Image()` of value 1 and populate it with zeros where `PopulationCount` is equal or lower than 100 people. In other words, we are creating a mask to remove pixels where there is less than 100 people, which is an indication that this area may not be a fully established settlement:

```{r eval=FALSE}
var popMask = ee.Image(1). where(PopulationCount.select(['population_count']).lte(100),0).clip(filteredAOI);
Map.addLayer(popMask.selfMask(), {palette:['green']}, 'Population Mask');
```

```{r PartIII-PopMask,  fig.cap= "Population mask created by selecting areas that have more than 100 people/pixel. Once this mask is applied, areas with less than 100 people per pixel will be masked.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-PopMask.png")
```

Next, we will use `settlements`. As you may have noticed, `settlements` contains the location of each small human settlement based on the 2007 census. We can then create a buffer of a certain size around each of these locations to create areas of likelihood for human settlements. We will first create a function to apply a buffer of a 1000 meters around the feature and then map it to `settlements` using `.map()` method:

```{r eval=FALSE}
var bufferSet = function(feature) {
  return feature.buffer(1000);   
};
var setLocation = settlements.map(bufferSet);
Map.addLayer(setLocation, {color:'purple'}, 'Settlements');
```

```{r PartIII-SetBuffer,  fig.cap= "1000 m buffer around each settlement location.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-SetBuffer.png")
```

Now, we can merge them into a final mask by creating an `ee.Image()` of 1 and clip it using the buffered locations and the `.clip()` method and add it to `popMask` using `.add()`:

```{r eval=FALSE}
var populationMask = ee.Image(1).clip(setLocation).unmask().add(popMask);
Map.addLayer(populationMask.selfMask(), {palette:'blue'}, 'Population Mask Final');
```

```{block, type='starcomment'}
Note that the code above used `.unmask()` after `.clip()`. In order to mathematically add two images, they have to have values. `.clip()` will cut an image for the extent of the feature used. Therefore, the rest will be automatically masked. Using `.unmask()` allows you to reaply 0 values to the masked areas, allowing you to do mathematical operations with it!
```

```{r PartIII-PopMaskFinal,  fig.cap= "Final population Mask.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-PopMaskFinal.png")
```

Finally, we will apply these masks to the composite:

```{r eval=FALSE}
var compositemasked = composite.mask(waterMask)
                              .updateMask(mangroveMask)
                              .updateMask(populationMask);

Map.addLayer(compositemasked, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite Masked');
```

```{r PartIII-MaskedCompositeII,  fig.cap= "Masked composite using `waterMask`, `mangroveMask` and `populationMask`.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-MaskedCompositeII.png")
```

C) Mask III - Index Threshold

As an additional mask, you can create a NBR-based mask to only highlight areas that are exposed and has no vegetation to it. Since we already applied the population and location based masks, this one can further remove extra pixels that are not likely to be human settlements, for instance, highly vegetated areas:

```{r eval=FALSE}
var bareMask = compositemasked.select('NBR').lte(0.25);
var compositeMasked = compositemasked.updateMask(bareMask);
Map.addLayer(compositeMasked, {bands: ['SR_B5', 'SR_B6', 'SR_B4'], min:0.1, max:0.2}, 'Composite Masked Final');
```

```{r PartIII-MaskedCompositeIII,  fig.cap= "Masked composite using `waterMask`, `mangroveMask` and `populationMask` and `bareMask` showing areas of higher likelihood to be human settlements.", echo=FALSE, message=FALSE}
knitr::include_graphics("images/PartIII-MaskedCompositeIII.png")
```
